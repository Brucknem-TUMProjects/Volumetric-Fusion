#pragma once

#ifndef _CAPTURE_DEVICE_
#define _CAPTURE_DEVICE_

#include <librealsense2/rs.hpp> // Include RealSense Cross Platform API
#include <map>
#include <iostream>
#include <string>
#include <thread>
#include <atomic>
#include <chrono>
#include "Data.hpp"
#include "Processing.hpp"

namespace vc::capture {

	/// <summary>
	/// Base class for capturing devices
	/// </summary>
	class CaptureDevice {
	public:
		rs2::config cfg;
		std::shared_ptr < vc::processing::Processing> processing;

		std::shared_ptr < vc::data::Data >data;
		std::shared_ptr<rs2::pipeline > pipeline;

		std::shared_ptr < std::atomic_bool> stopped;
		std::shared_ptr < std::atomic_bool> paused;
		std::shared_ptr < std::atomic_bool> calibrateCameras;

		std::shared_ptr < std::thread> thread;

		void startPipeline() {
			this->pipeline->start(this->cfg);
			this->data->setIntrinsics(this->pipeline->get_active_profile().get_stream(RS2_STREAM_COLOR).as<rs2::video_stream_profile>().get_intrinsics());
		}

		void pauseThread() {
			this->paused->store(true);
		}

		void resumeThread() {
			this->paused->store(false);
		}

		void stopThread() {
			this->stopped->store(true);
		}

		void calibrate(bool calibrate) {
			this->calibrateCameras->store(calibrate);
		}

		CaptureDevice(CaptureDevice& other) {
			this->data = other.data;
			this->processing = other.processing;
			this->pipeline = other.pipeline;
			this->cfg = other.cfg;

			this->stopped = other.stopped;
			this->paused = other.paused;
			this->calibrateCameras = other.calibrateCameras;
			this->thread = other.thread;
		}

		CaptureDevice(rs2::context context) {
			this->data = std::make_shared<vc::data::Data>();
			this->processing = std::make_shared<vc::processing::Processing>();
			this->pipeline = std::make_shared<rs2::pipeline>(context);
			this->stopped = std::make_shared<std::atomic_bool>(false);
			this->paused = std::make_shared<std::atomic_bool>(true);
			this->calibrateCameras = std::make_shared<std::atomic_bool>(false);

			this->thread = std::make_shared<std::thread>(&vc::capture::CaptureDevice::captureThreadFunction, this);
		}

		void captureThreadFunction() {
			rs2::align alignToColor(RS2_STREAM_COLOR);
			processing->startCharucoProcessing(data->camera);

			while (!stopped->load()) //While application is running
			{
				while (paused->load()) {
					continue;
				}

				try {
					rs2::frameset frameset = pipeline->wait_for_frames(); // Wait for next set of frames from the camera

					frameset = alignToColor.process(frameset);

					rs2::frame depthFrame = frameset.get_depth_frame(); //Take the depth frame from the frameset
					if (!depthFrame) { // Should not happen but if the pipeline is configured differently
						return;       //  it might not provide depth and we don't want to crash
					}

					rs2::frame filteredDepthFrame = depthFrame; // Does not copy the frame, only adds a reference

					rs2::frame colorFrame = frameset.get_color_frame();

					if (calibrateCameras->load()) {
						// Send color frame for processing
						processing->charucoProcessingBlocks->invoke(colorFrame);
						// Wait for results
						colorFrame = processing->charucoProcessingQueues.wait_for_frame();
					}

					data->filteredColorFrames = colorFrame;

					// Apply filters.
					/*for (auto&& filter : data->filters) {
						filteredDepthFrame = filter->process(filteredDepthFrame);
					}*/

					// Push filtered & original data to their respective queues
					data->filteredDepthFrames = filteredDepthFrame;

					data->points = data->pointclouds.calculate(depthFrame);  // Generate pointcloud from the depth data
					data->colorizedDepthFrames = data->colorizer.process(depthFrame);		// Colorize the depth frame with a color map
					data->pointclouds.map_to(data->colorizedDepthFrames);      // Map the colored depth to the point cloud

<<<<<<< HEAD
					data->vertices = Eigen::Matrix4Xd::Zero(4,data->points.size());
					for (int i = 0; i < data->points.size(); i++) {
						auto point = data->points.get_vertices()[i];
						data->vertices.col(i) << point.x, point.y, point.z, 1;
					}
=======
					auto startTime = std::chrono::steady_clock::now();

					auto pointCount = data->points.size();
					auto vertices = data->points.get_vertices();
					
					//float* fs = const_cast<float*>(reinterpret_cast<const float*>(vertices));

					//new (&this->data->vertices) Eigen::Map<Eigen::MatrixXf>(fs, 3, pointCount);
					
					//Eigen::Map<Eigen::MatrixXf> eigenVertices(fs, 3, pointCount);
					//this->data->vertices = Eigen::MatrixXd::Ones(4, pointCount);
					//this->data->vertices.block(0, 0, 3, pointCount) << eigenVertices.cast<double>();

					//this->data->vertices = Eigen::Map<Eigen::MatrixXf>(fs, 3, pointCount);

					/*data->vertices = Eigen::MatrixXd(4, pointCount);
					pointCount = pointCount - (pointCount % 5);
					// 64 KB cache lines, (4+4+4) * 5 = 60;
					for (int i = 0; i < pointCount; i+= 5) {
						data->vertices.block(0, i, 4, 5) <<
							vertices[i + 0].x, vertices[i + 0].y, vertices[i + 0].z, 1,
							vertices[i + 1].x, vertices[i + 1].y, vertices[i + 1].z, 1,
							vertices[i + 2].x, vertices[i + 2].y, vertices[i + 2].z, 1,
							vertices[i + 3].x, vertices[i + 3].y, vertices[i + 3].z, 1,
							vertices[i + 4].x, vertices[i + 4].y, vertices[i + 4].z, 1;
					}*/

					auto endTime = std::chrono::steady_clock::now();
					std::cout << "Elapsed time: " << std::chrono::duration_cast<std::chrono::milliseconds>(endTime - startTime).count() << " ms" << std::endl;
>>>>>>> kevin
				}
				catch (const std::exception & e) {
					std::stringstream stream;
					stream << "******************** THREAD ERROR *******************" << std::endl << e.what() << "****************************************************" << std::endl;
				}
			}
			this->pipeline->stop();
		}
	};

	/// <summary>
	/// A capture device for streaming the live RGB-D data from the device.
	/// </summary>
	/// <seealso cref="CaptureDevice" />
	class StreamingCaptureDevice : public CaptureDevice {
	public:
		StreamingCaptureDevice(rs2::context context, rs2::device device) :
			CaptureDevice(context)
		{
			data->deviceName = device.get_info(RS2_CAMERA_INFO_SERIAL_NUMBER);

			this->cfg.enable_device(data->deviceName);
			this->cfg.enable_all_streams();
		}
	};

	/// <summary>
	///  A capture device for streaming the live RGB-D data from the device and to record it to a file.
	/// </summary>
	/// <seealso cref="StreamingCaptureDevice" />
	class RecordingCaptureDevice : public StreamingCaptureDevice {
	public:
		RecordingCaptureDevice(rs2::context context, rs2::device device, std::string foldername) :
			StreamingCaptureDevice(context, device)
		{
			this->cfg.enable_device(data->deviceName);
			this->cfg.enable_all_streams();
			this->cfg.enable_record_to_file(foldername + data->deviceName + ".bag");
		}
	};

	/// <summary>
	///  A capture device for streaming the RGB-D data from a file.
	/// </summary>
	/// <seealso cref="CaptureDevice" />
	class PlayingCaptureDevice : public CaptureDevice {
	public:
		PlayingCaptureDevice(rs2::context context, std::string filename) :
			CaptureDevice(context)
		{
			data->deviceName = filename;

			this->cfg.enable_device_from_file(data->deviceName);
			this->cfg.enable_all_streams();
		}
	};
}

#endif // !_CAPTURE_DEVICE_